import os, json
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from PIL import Image, ImageDraw
from matplotlib import pyplot as plt
from PIL import Image

# ---------------------------
DATA_DIR = "/kaggle/input/unet-vgg16-longxuyen-vehicles/Resized_images/Resized_images"
IMG_SIZE = (448, 448)
BATCH_SIZE = 16
EPOCHS = 100
LR = 1e-4
SAVE_PATH = "unet_vgg16_multiclass_best_5_class.h5"
AUTOTUNE = tf.data.AUTOTUNE

class_map = {
    "Background": 0,
    "Xe đạp": 1,
    "Xe bốn bánh": 2,
    "Xe máy": 3,
    "Phương tiện khác": 4
}
N_CLASSES = len(class_map)


def create_mask_from_json(json_path, target_size, class_map):
    with open(json_path, 'r') as f:
        data = json.load(f)

    h = data.get("imageHeight", target_size[1])
    w = data.get("imageWidth", target_size[0])
    mask = Image.new('L', (w, h), 0)
    draw = ImageDraw.Draw(mask)

    for shape in data["shapes"]:
        label = shape["label"]
        if label not in class_map:
            continue
        class_id = class_map[label]
        points = [tuple(p) for p in shape["points"]]
        draw.polygon(points, outline=class_id, fill=class_id)

    mask = mask.resize(target_size, Image.NEAREST)
    return np.array(mask, dtype=np.uint8)

def load_image_and_mask(img_path):
    img_path = img_path.numpy().decode("utf-8")
    img_name = os.path.basename(img_path)
    json_path = os.path.join(DATA_DIR, os.path.splitext(img_name)[0] + ".json")

    img = load_img(img_path, target_size=IMG_SIZE)
    img = img_to_array(img) / 255.0

    mask = create_mask_from_json(json_path, IMG_SIZE, class_map)
    mask = to_categorical(mask, num_classes=N_CLASSES)

    return img.astype(np.float32), mask.astype(np.float32)

def tf_load_data(img_path):
    img, mask = tf.py_function(
        func=load_image_and_mask,
        inp=[img_path],
        Tout=[tf.float32, tf.float32]
    )
    img.set_shape((IMG_SIZE[1], IMG_SIZE[0], 3))
    mask.set_shape((IMG_SIZE[1], IMG_SIZE[0], N_CLASSES))
    return img, mask

# ===== Metrics =====
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1, N_CLASSES])
    y_pred_f = tf.reshape(y_pred, [-1, N_CLASSES])
    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)
    dice = (2. * intersection + smooth) / (
        tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0) + smooth)
    return tf.reduce_mean(dice)

def iou_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1, N_CLASSES])
    y_pred_f = tf.reshape(y_pred, [-1, N_CLASSES])
    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)
    union = tf.reduce_sum(y_true_f + y_pred_f, axis=0) - intersection
    iou = (intersection + smooth) / (union + smooth)
    return tf.reduce_mean(iou)

# ===== Weighted CE Loss =====
class_weights = tf.constant([0.2, 1.0, 1.0, 1.2, 1.2], dtype=tf.float32)

def weighted_cce(y_true, y_pred):
    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)
    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred) * class_weights, axis=-1)
    return tf.reduce_mean(loss)

# ===== Dice Loss =====
def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

# ===== Total Loss =====
def total_loss(y_true, y_pred):
    return weighted_cce(y_true, y_pred) + dice_loss(y_true, y_pred)



def unet_vgg16(input_shape=(448, 448, 3), num_classes=4):
    base_model = tf.keras.applications.VGG16(
        weights="imagenet",
        include_top=False,
        input_shape=input_shape
    )

    # Lấy các feature map của VGG16
    block1 = base_model.get_layer("block1_conv2").output
    block2 = base_model.get_layer("block2_conv2").output
    block3 = base_model.get_layer("block3_conv3").output
    block4 = base_model.get_layer("block4_conv3").output
    block5 = base_model.get_layer("block5_conv3").output

    up6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding="same")(block5)
    up6 = tf.keras.layers.concatenate([up6, block4])
    conv6 = tf.keras.layers.Conv2D(512, (3, 3), activation="relu", padding="same")(up6)
    conv6 = tf.keras.layers.Conv2D(512, (3, 3), activation="relu", padding="same")(conv6)

    up7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding="same")(conv6)
    up7 = tf.keras.layers.concatenate([up7, block3])
    conv7 = tf.keras.layers.Conv2D(256, (3, 3), activation="relu", padding="same")(up7)
    conv7 = tf.keras.layers.Conv2D(256, (3, 3), activation="relu", padding="same")(conv7)

    up8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding="same")(conv7)
    up8 = tf.keras.layers.concatenate([up8, block2])
    conv8 = tf.keras.layers.Conv2D(128, (3, 3), activation="relu", padding="same")(up8)
    conv8 = tf.keras.layers.Conv2D(128, (3, 3), activation="relu", padding="same")(conv8)

    up9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding="same")(conv8)
    up9 = tf.keras.layers.concatenate([up9, block1])
    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation="relu", padding="same")(up9)
    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation="relu", padding="same")(conv9)

    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation="softmax")(conv9)
    model = tf.keras.Model(inputs=base_model.input, outputs=outputs)

    return model

def main():
    all_image = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR)
                 if f.lower().endswith((".jpg", ".png", ".jpeg"))]
    np.random.shuffle(all_image)
    split = int(0.8 * len(all_image))
    train_imgs, val_imgs = all_image[:split], all_image[split:]

    train_ds = tf.data.Dataset.from_tensor_slices(train_imgs).map(tf_load_data, num_parallel_calls=AUTOTUNE).shuffle(128).batch(BATCH_SIZE).prefetch(AUTOTUNE)
    val_ds = tf.data.Dataset.from_tensor_slices(val_imgs).map(tf_load_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)

    model = unet_vgg16(input_shape=(*IMG_SIZE,3), num_classes=N_CLASSES)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(LR),
        loss=total_loss,
        metrics=[dice_coef, iou_coef, "accuracy"]
    )


    callbacks = [
        ModelCheckpoint(SAVE_PATH, monitor='val_dice_coef', save_best_only=True, mode='max'),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),
        EarlyStopping(monitor='val_dice_coef', patience=3, mode='max', restore_best_weights=True)
    ]

    print("Start training on GPU:", tf.config.list_physical_devices('GPU'))

    with tf.device('/GPU:0'):
        history = model.fit(
            train_ds,
            validation_data=val_ds,
            epochs=EPOCHS,
            callbacks=callbacks
        )

    # Plot Loss
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.legend()
    plt.title("Loss")
    plt.show()
    
    # Plot Dice
    plt.plot(history.history['dice_coef'], label='Train Dice')
    plt.plot(history.history['val_dice_coef'], label='Val Dice')
    plt.legend()
    plt.title("Dice Coefficient")
    plt.show()
    
    # Plot IoU
    plt.plot(history.history['iou_coef'], label='Train IoU')
    plt.plot(history.history['val_iou_coef'], label='Val IoU')
    plt.legend()
    plt.title("IoU")
    plt.show()


    model.save("unet_vgg16_multiclass_final_5_class.h5")
    print("Training done. Model saved!")

if __name__ == "__main__":
    main()
